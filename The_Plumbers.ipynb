{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "smFML1JtPYFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "2zxkbwlzQvWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import json\n",
        "import re\n",
        "\n",
        "openai.api_key = '###'"
      ],
      "metadata": {
        "id": "6FvHnX3qQgHm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(system_prompt, user_prompt, model = 'gpt-3.5-turbo', temperature = 0, verbose = False):\n",
        "    ''' Normal call of OpenAI API '''\n",
        "    response = openai.ChatCompletion.create(\n",
        "    temperature = temperature,\n",
        "    model=model,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ])\n",
        "\n",
        "    res = response['choices'][0]['message']['content']\n",
        "\n",
        "    if verbose:\n",
        "        print('System prompt:', system_prompt)\n",
        "        print('User prompt:', user_prompt)\n",
        "        print('GPT response:', res)\n",
        "\n",
        "    return res"
      ],
      "metadata": {
        "id": "YpekOmBSQmNc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat(system_prompt='You are to classify if a number is even or odd', user_prompt = '4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3Mtc-epBQnrR",
        "outputId": "08256433-a28d-417a-f099-16dcd30e614e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The number 4 is even.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import IPython.display\n",
        "from PIL import Image\n",
        "import base64\n",
        "import requests, json\n",
        "import gradio as gr\n",
        "requests.adapters.DEFAULT_TIMEOUT = 60"
      ],
      "metadata": {
        "id": "aVuxzOnFQrqs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = '''Background\n",
        "Python programm\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "c_Zlh_YfQuCZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_chat_prompt(message, chat_history, max_convo_length):\n",
        "    prompt = \"\"\n",
        "    for turn in chat_history[-max_convo_length:]:\n",
        "        user_message, bot_message = turn\n",
        "        prompt = f\"{prompt}\\nUser: {user_message}\\nAssistant: {bot_message}\"\n",
        "    prompt = f\"{prompt}\\nUser: {message}\\nAssistant:\"\n",
        "    return prompt\n",
        "\n",
        "def respond(message, chat_history, max_convo_length = 10):\n",
        "        formatted_prompt = format_chat_prompt(message, chat_history, max_convo_length)\n",
        "        print('Prompt + Context:')\n",
        "        print(formatted_prompt)\n",
        "        bot_message = chat(system_prompt = f'''You are a junior developer bot who is still learning. You are paired with the user for paired programming assignment.\n",
        "You will always generate syntax wrong code, but you will correct the code once the user tells you to.''',\n",
        "                           user_prompt = formatted_prompt)\n",
        "        chat_history.append((message, bot_message))\n",
        "        return \"\", chat_history\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot(height=300) #just to fit the notebook\n",
        "    msg = gr.Textbox(label=\"Prompt\")\n",
        "    with gr.Accordion(label=\"Advanced options\",open=True):\n",
        "        system = gr.Textbox(label=\"System message\", lines=2, value=\"A conversation between a user and an LLM-based AI assistant. The assistant gives helpful and honest answers.\")\n",
        "        temperature = gr.Slider(label=\"temperature\", minimum=0.1, maximum=1, value=0.7, step=0.1)\n",
        "    btn = gr.Button(\"Submit\")\n",
        "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
        "\n",
        "    btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
        "    msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot]) #Press enter to submit\n",
        "gr.close_all()\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "gZ_P4qqCQ9L3",
        "outputId": "73d10fd3-37f0-4982-aed8-3f346a73b685"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/blocks.py:902: UserWarning: api_name respond already exists, using respond_1\n",
            "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://d629160e54c322884e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d629160e54c322884e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H4fzPsEeS_MX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}